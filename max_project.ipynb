{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *\n",
    "import datetime\n",
    "\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk.data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = ['/home/ubuntu/nlp/nlp_lit/literature/dostoevsky/the_idiot/', \n",
    "         '/home/ubuntu/nlp/nlp_lit/literature/dostoevsky/the_brothers_karamazov/', \n",
    "         '/home/ubuntu/nlp/nlp_lit/literature/dostoevsky/crime_and_punishment/', \n",
    "        '/home/ubuntu/nlp/nlp_lit/literature/tolstoy/war_and_peace/', \n",
    "         '/home/ubuntu/nlp/nlp_lit/literature/tolstoy/anna_karenina/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from `overall_sentiment.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "The Idiot\n",
    "    {'neg': 0.099, 'neu': 0.769, 'pos': 0.132, 'compound': 1.0}\n",
    "\n",
    "The Brothers Karamazov\n",
    "    {'neg': 0.116, 'neu': 0.757, 'pos': 0.128, 'compound': 1.0}\n",
    "\n",
    "Crime and Punishment\n",
    "    {'neg': 0.115, 'neu': 0.778, 'pos': 0.107, 'compound': -1.0}\n",
    "\n",
    "War and Peace\n",
    "    {'neg': 0.092, 'neu': 0.796, 'pos': 0.111, 'compound': 1.0}\n",
    "\n",
    "Anna Karenina\n",
    "    {'neg': 0.088, 'neu': 0.789, 'pos': 0.123, 'compound': 1.0}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(path):\n",
    "    \n",
    "    # Work name\n",
    "    name = path.split('/')[-2]\n",
    "    \n",
    "    time_start = datetime.datetime.now()\n",
    "    \n",
    "    # Data\n",
    "    data = (TextList.from_folder(Path(path))\n",
    "        .split_by_rand_pct(0.1, seed=42)\n",
    "        .label_for_lm()\n",
    "        .databunch(bs=48))\n",
    "    \n",
    "    # Pretrained Wiki Model \n",
    "    lm = language_model_learner(data, AWD_LSTM, drop_mult=0.3)\n",
    "    \n",
    "    # Learning Rate via lr finder\n",
    "    lr = 1e-3\n",
    "    \n",
    "    # For training efficiency\n",
    "    lm.to_fp16();\n",
    "    \n",
    "    # Train last layers with high learning rate\n",
    "    lm.fit_one_cycle(1, lr*10, moms=(0.8,0.7))\n",
    "    \n",
    "    # Train all layers for 10 epochs\n",
    "    lm.unfreeze()\n",
    "    lm.fit_one_cycle(10, lr, moms=(0.8,0.7))\n",
    "    \n",
    "    # Save weights\n",
    "    lm.save('weights')\n",
    "    \n",
    "    # Write out update\n",
    "    time_end = datetime.datetime.now()\n",
    "    print(f'Took {(time_end - time_start).total_seconds() / 60 } minutes\\n')\n",
    "    print(f'DONE')\n",
    "        \n",
    "    return lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### War & Peace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.725107</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.476871</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.368428</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.162788</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.905936</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.659311</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.426557</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.214016</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.102007</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.994689</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.949026</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained war_and_peace at 2019-06-21 22:51:30.866527\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-4b5264937330>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/ubuntu/nlp/nlp_lit/literature/tolstoy/war_and_peace/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-32160e4a4181>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mtime_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Trained {name} at {datetime.datetime.now()}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Took {(time2 - time1).total_seconds() / 60 } minutes\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'DONE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time2' is not defined"
     ]
    }
   ],
   "source": [
    "path = '/home/ubuntu/nlp/nlp_lit/literature/tolstoy/war_and_peace/'\n",
    "lm = train_model(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate Sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.load('weights');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence(model, intro, n_words, temperature): \n",
    "    \"\"\"\n",
    "    Lowering temperature will make the texts less randomized.\n",
    "    \"\"\"\n",
    "    sentence = model.predict(intro, n_words, temperature=temperature)\n",
    "    return sentence.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_period(sentence):\n",
    "    for i, letter in enumerate(reversed(sentence)):\n",
    "        if letter == '.':\n",
    "            return len(sentence) - i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    sentence = sentence.replace(' ,', ',')\n",
    "    sentence = sentence.replace(' ?', '?')\n",
    "    sentence = sentence.replace(' .', '.')\n",
    "    sentence = sentence.replace('( ', '(')\n",
    "    sentence = sentence.replace(' )', ')')\n",
    "    sentence = sentence.replace('“ ', '“')\n",
    "    sentence = sentence.replace(\" ’\", \"’\")\n",
    "    sentence = sentence.replace(\" '\", \"'\")    \n",
    "    sentence = sentence.replace(\" :\", \":\")\n",
    "    sentence = sentence.replace(' ”', '”')\n",
    "    sentence = sentence.replace('   ', ' ')\n",
    "    sentence = sentence.replace('  ', ' ')\n",
    "    sentence = sentence.replace(\" n’t\", \"n’t\")\n",
    "    sentence = sentence.replace(' i ', ' I ')\n",
    "    \n",
    "    # clip to full sentence \n",
    "    return sentence[:last_period(sentence)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a bunch of sentences & calculate the score of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scored_sentences(n, model, intro, words, temperature):\n",
    "    results = pd.DataFrame(columns=['sentence', 'sentiment'])\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    for i in range(n):\n",
    "        sentence = clean_sentence(generate_sentence(model, intro, words, temperature))\n",
    "        sentiment = sid.polarity_scores(sentence)['compound']\n",
    "        results.loc[i] = [sentence, sentiment]\n",
    "    results.sort_values('sentiment', ascending=False, inplace=True)\n",
    "    results = results.reset_index().drop('index', axis=1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generated Sentiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'anna_karenina':pd.read_csv('anna_karenina.csv'), \n",
    "          'war_and_peace':pd.read_csv('war_and_peace.csv'),\n",
    "          'the_brothers_karamazov':pd.read_csv('the_brothers_karamazov.csv'), \n",
    "          'crime_and_punishment':pd.read_csv('crime_and_punishment.csv'), \n",
    "          'the_idiot':pd.read_csv('the_idiot.csv')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_sentiment_score(path):\n",
    "    \n",
    "    # Load tokenizer details\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    \n",
    "    # Create analyzer object\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    # Read in data\n",
    "    with open(path, 'r') as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    # Break up text into sentences\n",
    "    sentences = tokenizer.tokenize(data)\n",
    "    \n",
    "    # Calculate average sentiment score\n",
    "    total_score = 0.0\n",
    "    for sentence in sentences: \n",
    "        total_score += analyzer.polarity_scores(sentence)['compound']\n",
    "    \n",
    "    return total_score / len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = ['/home/ubuntu/nlp/nlp_lit/literature/tolstoy/anna_karenina/anna_karenina.txt', \n",
    "         '/home/ubuntu/nlp/nlp_lit/literature/tolstoy/war_and_peace/war_and_peace.txt',\n",
    "         '/home/ubuntu/nlp/nlp_lit/literature/dostoevsky/crime_and_punishment/crime_and_punishment.txt',\n",
    "         '/home/ubuntu/nlp/nlp_lit/literature/dostoevsky/the_brothers_karamazov/the_brothers_karamazov.txt',\n",
    "         '/home/ubuntu/nlp/nlp_lit/literature/dostoevsky/the_idiot/the_idiot.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real vs. Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work:          anna_karenina\n",
      "Gen Score:     0.0832\n",
      "Real Score:    0.0909\n",
      "\n",
      "Work:          war_and_peace\n",
      "Gen Score:     0.0498\n",
      "Real Score:    0.0029\n",
      "\n",
      "Work:          crime_and_punishment\n",
      "Gen Score:     -0.0125\n",
      "Real Score:    -0.0087\n",
      "\n",
      "Work:          the_brothers_karamazov\n",
      "Gen Score:     0.0106\n",
      "Real Score:    0.0036\n",
      "\n",
      "Work:          the_idiot\n",
      "Gen Score:     0.0594\n",
      "Real Score:    -0.0009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for path in works: \n",
    "    print(f'Work:          {path.split(\"/\")[-2]}')\n",
    "    print(f'Gen Score:     {np.round(get_mean_sentiment_score(path), 4)}')\n",
    "    print(f'Real Score:    {np.round(results[path.split(\"/\")[-2]][\"sentiment\"].mean(), 4)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(results['the_idiot']['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the afternoon and evening it was as usual that a fellow for one of those old miserable women of late century had met such a bad business husband as he\n"
     ]
    }
   ],
   "source": [
    "i-=1\n",
    "\n",
    "print(sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the afternoon one of his classes was killed by the indignant traveller Ismailofsky.\n"
     ]
    }
   ],
   "source": [
    "print(sentences[i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
